{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_bases = ['https://wwwn.cdc.gov/nchs/nhanes/search/variablelist.aspx?Component=Demographics&Cycle=', \n",
    "             'https://wwwn.cdc.gov/nchs/nhanes/search/variablelist.aspx?Component=Dietary&Cycle=',\n",
    "             'https://wwwn.cdc.gov/nchs/nhanes/search/variablelist.aspx?Component=Examination&Cycle=',\n",
    "             'https://wwwn.cdc.gov/nchs/nhanes/search/variablelist.aspx?Component=Laboratory&Cycle=',\n",
    "             'https://wwwn.cdc.gov/nchs/nhanes/search/variablelist.aspx?Component=Questionnaire&Cycle=',\n",
    "             ]\n",
    "years = ['1999-2000', '2001-2002', '2003-2004', '2005-2006', '2007-2008', '2009-2010', '2011-2012', '2013-2014', '2015-2016', '2017-2018']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in years:\n",
    "    df = pd.DataFrame(columns=['var_name', 'file_name'])\n",
    "    for url_base in url_bases:\n",
    "        url = url_base + year\n",
    "        request = requests.get(url)\n",
    "        soup = BeautifulSoup(request.text, 'html.parser')\n",
    "        \n",
    "        for tag in soup.find_all('tr'):\n",
    "            row = []\n",
    "            for inner_tag in tag.find_all('td'):\n",
    "                row.append(inner_tag.text.strip())\n",
    "            if len(row) > 0:\n",
    "                df = df.append({'var_name': row[0], 'file_name': row[2] + '.XPT'}, ignore_index=True)\n",
    "        \n",
    "    df.to_csv('data/' + year + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_var_file_dict(data):\n",
    "    var_file_dict = {}\n",
    "    for index, row in data.iterrows():\n",
    "        var_file_dict[row['var_name']] = row['file_name']\n",
    "    return var_file_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Output.txt\", \"w\") as text_file:\n",
    "    for year in years:\n",
    "        year_data = pd.read_csv('data/' + year + '.csv')\n",
    "        var_file_map = make_var_file_dict(year_data)\n",
    "        print(f\"VAR_TO_FILENAME_{year} = {var_file_map}\", file=text_file)\n",
    "    print(\"\\n\\n\", file=text_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
